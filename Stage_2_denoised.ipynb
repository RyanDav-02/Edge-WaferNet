{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening LSWMD.pkl using legacy byte-stream decoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajith\\AppData\\Local\\Temp\\ipykernel_36652\\35077386.py:28: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  data = pickle.load(f, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded 25519 defect samples.\n",
      "\n",
      "Starting Training...\n",
      "Epoch 1/10\n",
      "\u001b[1m 319/1276\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.5225 - loss: 1.4166"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ==========================================\n",
    "# 1. LEGACY COMPATIBILITY FIXES\n",
    "# ==========================================\n",
    "import pandas.core.indexes as indexes\n",
    "sys.modules['pandas.indexes'] = indexes\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA LOADING & PREPROCESSING\n",
    "# ==========================================\n",
    "def load_and_preprocess():\n",
    "    file_path = 'LSWMD.pkl'\n",
    "    if os.path.exists(file_path):\n",
    "        print(\"Opening LSWMD.pkl using legacy byte-stream decoding...\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f, encoding='latin1')\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Clean labels\n",
    "        df['failureType'] = df['failureType'].apply(\n",
    "            lambda x: x[0][0] if isinstance(x, (list, np.ndarray)) and len(x) > 0 else 'none'\n",
    "        )\n",
    "        # Filter for actual defects\n",
    "        df_defects = df[df['failureType'] != 'none'].copy()\n",
    "        print(f\"✅ Successfully loaded {len(df_defects)} defect samples.\")\n",
    "    else:\n",
    "        # Fallback Test Data\n",
    "        print(\"⚠️ File not found, generating synthetic data...\")\n",
    "        test_data = {'waferMap': [np.random.randint(0, 3, (26, 26)) for _ in range(500)],\n",
    "                     'failureType': [np.random.choice(['Center', 'Donut', 'Scratch']) for _ in range(500)]}\n",
    "        df_defects = pd.DataFrame(test_data)\n",
    "\n",
    "    # Label Mapping\n",
    "    label_map = {val: i for i, val in enumerate(df_defects['failureType'].unique())}\n",
    "    df_defects['label_id'] = df_defects['failureType'].map(label_map)\n",
    "    \n",
    "    # Preprocessing Pipeline\n",
    "    processed_images = []\n",
    "    for x in df_defects['waferMap']:\n",
    "        denoised = ndimage.median_filter(x, size=2)\n",
    "        resized = tf.image.resize(denoised[:, :, np.newaxis], (28, 28)).numpy()\n",
    "        processed_images.append(resized)\n",
    "    \n",
    "    X = np.array(processed_images).astype('float32') / 2.0\n",
    "    y = tf.keras.utils.to_categorical(df_defects['label_id'])\n",
    "    return X, y, label_map\n",
    "\n",
    "# Run Loading\n",
    "X, y, label_map = load_and_preprocess()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==========================================\n",
    "# 3. THE EDGE-AI ARCHITECTURE\n",
    "# ==========================================\n",
    "\n",
    "def build_precision_model(num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.SeparableConv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.2), \n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_precision_model(len(label_map))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ==========================================\n",
    "# 4. TRAINING & EXPORT\n",
    "# ==========================================\n",
    "print(\"\\nStarting Training...\")\n",
    "# We save the 'history' object here so it is defined for the plots below\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Quantization for NXP eIQ\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "with open('wafer_defect_edge.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# ==========================================\n",
    "# 5. VISUALIZATION (RESULTS)\n",
    "# ==========================================\n",
    "def plot_results(history, model, X_test, y_test, label_map):\n",
    "    # 1. Accuracy/Loss Curves\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    ax1.plot(history.history['accuracy'], label='Train')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Val')\n",
    "    ax1.set_title('Accuracy'); ax1.legend()\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Train')\n",
    "    ax2.plot(history.history['val_loss'], label='Val')\n",
    "    ax2.set_title('Loss'); ax2.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Confusion Matrix\n",
    "    \n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
    "                xticklabels=label_map.keys(), yticklabels=label_map.keys())\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.show()\n",
    "    \n",
    "    print(\"\\n--- Numerical Precision Report ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=list(label_map.keys())))\n",
    "\n",
    "# RUN VISUALS\n",
    "plot_results(history, model, X_test, y_test, label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
